{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHEF environmental footprint model\n",
    "\n",
    "The following script calculates the environmental footprint of apartments (also called, dwellings) and occupants (also called, tenants or households) of the apartments for specific buildings owned by the <a href=http://www.nrp73.ch/en/projects/building-construction/ecological-footprint-in-the-housing-sector>Shrinking Housing Environmental Footprint</a> (SHEF, under <a href=http://www.snf.ch/en/researchinFocus/nrp/nfp-73/Pages/default.aspx>NRP73: Sustainable Economy</a>) project building-owner partners: <a href=https://www.abz.ch/>ABZ</a>, <a href=https://www.mobiliar.ch/>Swiss Mobiliar</a> and <a href=https://www.schl.ch/>SCHL</a>. \n",
    "\n",
    "_Input_: Data from HBS (<a href = https://www.bfs.admin.ch/bfs/en/home/statistics/economic-social-situation-population/surveys/hbs.html>obtain from Federal Statistical Office of Switzerland</a>) and STATPOP (census) - linked to limited GWR (from <a href='https://www.bfs.admin.ch/bfs/en/home/registers/federal-register-buildings-dwellings.html'>Federal register of buildings</a>) SHEF partner buildings\n",
    "\n",
    "_Run_: The Jupyter Notebook provides a step-by-step guidance to do the computations\n",
    "\n",
    "_Output_: One CSV with extended columns (to input file) with occupant and associated apartment (heating and material) footprints \n",
    "\n",
    "TOC - overview image below:<a id=\"toc-main\"></a>\n",
    "- <a href=\"#abm\"> Step 0: Initialising with HBS, STATPOP and GWR tenant-dwelling pairs</a>\n",
    "- <a href=\"#consumption\"> Step 1: Calculation of occupants' consumption-based footprint</a>\n",
    "- <a href=\"#material\"> Step 2: Calculation of apartments' material and renovation based footprint</a>\n",
    "- <a href=\"#energy\"> Step 3: Calculation of apartments' energy(heat/ warmwater)-based footprint</a>\n",
    "- <a href=\"#total_impacts\"> Step 4: Merge all the final results </a>\n",
    "\n",
    "Author: Rhythima Shinde, ETH Zurich\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plan/datapipeline-2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialisation: output of ABMs  <a id=\"abm\"></a>\n",
    "\n",
    "<a href=\"#toc-main\">back</a>\n",
    "\n",
    "In this section, the outputs from following the ABMs are prepared in a format to be passed as input in the respective models \n",
    "1. Tenant ABM output (household information) for Consumption footrprint\n",
    "2. Owner ABM output (building information) for Apartment footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST ######\n",
    "\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "file = open('model_consumption/Household-Model-Development/init_data/allhhscardemand.pickle','rb')\n",
    "x = pickle.load(file)\n",
    "with open('model_consumption/Household-Model-Development/init_data/allhhscardemand.csv', 'w') as output:\n",
    "    writer = csv.writer(output)\n",
    "    for key, value in x.items():\n",
    "        writer.writerow([key, value])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.stats as stats\n",
    "import statistics\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "import random \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.multioutput as sko\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# import brightway2 as bw #TODO when running LCA for the rebound model here\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['btype',\n",
       " 'bid',\n",
       " 'bfsnr',\n",
       " 'x',\n",
       " 'y',\n",
       " 'elevation',\n",
       " 'delta02',\n",
       " 'delta10',\n",
       " 'delta20',\n",
       " 'area',\n",
       " 'cells',\n",
       " 'p0',\n",
       " 'p5',\n",
       " 'p10',\n",
       " 'p15',\n",
       " 'p20',\n",
       " 'p25',\n",
       " 'p30',\n",
       " 'p35',\n",
       " 'p40',\n",
       " 'p45',\n",
       " 'p50',\n",
       " 'p55',\n",
       " 'p60',\n",
       " 'p65',\n",
       " 'p70',\n",
       " 'p75',\n",
       " 'p80',\n",
       " 'p85',\n",
       " 'p90',\n",
       " 'p95',\n",
       " 'p100',\n",
       " 'p1',\n",
       " 'p2',\n",
       " 'p3',\n",
       " 'p4',\n",
       " 'p96',\n",
       " 'p97',\n",
       " 'p98',\n",
       " 'p99',\n",
       " 'pavg',\n",
       " 'pcount',\n",
       " 'pe0',\n",
       " 'pe5',\n",
       " 'pe10',\n",
       " 'pe15',\n",
       " 'pe20',\n",
       " 'pe25',\n",
       " 'pe30',\n",
       " 'pe35',\n",
       " 'pe40',\n",
       " 'pe45',\n",
       " 'pe50',\n",
       " 'pe55',\n",
       " 'pe60',\n",
       " 'pe65',\n",
       " 'pe70',\n",
       " 'pe75',\n",
       " 'pe80',\n",
       " 'pe85',\n",
       " 'pe90',\n",
       " 'pe95',\n",
       " 'pe100',\n",
       " 'pe1',\n",
       " 'pe2',\n",
       " 'pe3',\n",
       " 'pe4',\n",
       " 'pe96',\n",
       " 'pe97',\n",
       " 'pe98',\n",
       " 'pe99',\n",
       " 'peavg',\n",
       " 'pecount',\n",
       " 'el0',\n",
       " 'el5',\n",
       " 'el10',\n",
       " 'el15',\n",
       " 'el20',\n",
       " 'el25',\n",
       " 'el30',\n",
       " 'el35',\n",
       " 'el40',\n",
       " 'el45',\n",
       " 'el50',\n",
       " 'el55',\n",
       " 'el60',\n",
       " 'el65',\n",
       " 'el70',\n",
       " 'el75',\n",
       " 'el80',\n",
       " 'el85',\n",
       " 'el90',\n",
       " 'el95',\n",
       " 'el100',\n",
       " 'el1',\n",
       " 'el2',\n",
       " 'el3',\n",
       " 'el4',\n",
       " 'el96',\n",
       " 'el97',\n",
       " 'el98',\n",
       " 'el99',\n",
       " 'elavg',\n",
       " 'elcount',\n",
       " 'slope0',\n",
       " 'slope5',\n",
       " 'slope10',\n",
       " 'slope15',\n",
       " 'slope20',\n",
       " 'slope25',\n",
       " 'slope30',\n",
       " 'slope35',\n",
       " 'slope40',\n",
       " 'slope45',\n",
       " 'slope50',\n",
       " 'slope55',\n",
       " 'slope60',\n",
       " 'slope65',\n",
       " 'slope70',\n",
       " 'slope75',\n",
       " 'slope80',\n",
       " 'slope85',\n",
       " 'slope90',\n",
       " 'slope95',\n",
       " 'slope100',\n",
       " 'slope1',\n",
       " 'slope2',\n",
       " 'slope3',\n",
       " 'slope4',\n",
       " 'slope96',\n",
       " 'slope97',\n",
       " 'slope98',\n",
       " 'slope99',\n",
       " 'slopeavg',\n",
       " 'slopecount',\n",
       " 'volume',\n",
       " 'avg_height',\n",
       " 'avg_height_1',\n",
       " 'volume_minelev',\n",
       " 'avg_height_minelev',\n",
       " 'min_elev',\n",
       " 'perimeter',\n",
       " 'perimeter_minh',\n",
       " 'perimeter_avgh',\n",
       " 'perimeter_maxh',\n",
       " 'perimeter_medh',\n",
       " 'mar_ratio',\n",
       " 'mar_angle',\n",
       " 'ds',\n",
       " 'geom']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gws_test = pd.read_csv('model_rene_buildinginfo/Buildinginfo.csv',delimiter= \",\",encoding='ISO-8859–1' )\n",
    "list(gws_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "521.376550661"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gws_test['volume'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:blue'>USER INPUT NEEDED to chose the strategy no</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Strategy_no = 0\n",
    "\n",
    "# for building model :  oil: 50%, gas: 15%, dis.: 5%, ren: 15%, heatpump 15%\n",
    "# 0, 1 , NO CHANGE\n",
    "# 2 , oil to district : oil: -10%, dis.: +10%\n",
    "# 3 , oil to district and renw: oil: -25%, dis.: +5%, ren: +5%, heatpump +15%\n",
    "# 4 , oil to district and renw(more): oil: -40%, gas: +10%, dis.: +20%, ren: 15%, heatpump +10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapt the owner ABM output files further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0) Take Owner ABM output file\n",
    "pd_owner_raw = pd.read_csv('model_owner_ABM/strategy'+str(Strategy_no)+'_output_dw_model.csv',\n",
    "                           delimiter=',', error_bad_lines=False, encoding='ISO-8859–1')\n",
    "print(pd_owner_raw.head(),list(pd_owner_raw.columns))\n",
    "\n",
    "pd_intergation_ownr = pd.read_excel('model_owner_ABM/integration_OwnerABM_Buildingmodel_1.xlsx')\n",
    "\n",
    "# (1) drop the unwanted columns\n",
    "pd_intergation_ownr_list_drop = list(pd_intergation_ownr['variables from owner ABM'])\n",
    "pd_owner_raw=pd_owner_raw[pd_intergation_ownr_list_drop]\n",
    "\n",
    "# (2) rename the columns\n",
    "pd_intergation_ownr_list_renamed = list(pd_intergation_ownr['Inputs for building model '])\n",
    "pd_owner_raw.columns = pd_intergation_ownr_list_renamed\n",
    "pd.DataFrame.to_csv(pd_owner_raw,'model_owner_ABM/dwelling_data_1.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach the tenant and the owner ABM output files <a id = 'dwelling_area'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tenant_raw = pd.read_csv('model_tenant_ABM/strategy'+str(Strategy_no)+'_households_data.csv', sep=',')\n",
    "pd_owner_raw = pd.read_csv('model_owner_ABM/dwelling_data_1.csv', sep=',')\n",
    "\n",
    "pd_owner_raw_columns = list(pd_owner_raw.columns)\n",
    "pd_tenant_raw_columns = list(pd_tenant_raw.columns)\n",
    "\n",
    "print('owner-columns=', pd_owner_raw_columns ,len(pd_owner_raw_columns),\n",
    "      '\\n\\ntenant-columns=',pd_tenant_raw_columns,len(pd_tenant_raw_columns))\n",
    "\n",
    "pd_owner_tenant_raw = pd.merge(pd_owner_raw,pd_tenant_raw, left_on= ['Time step','Dwelling id'],\n",
    "                               right_on= ['Step','Current dwelling id'] )\n",
    "\n",
    "\n",
    "#check if the match is correct based on dwelling sizes\n",
    "area_tenant_file = [np.round(i) for i in list(pd_owner_tenant_raw['Dwelling area'])]\n",
    "area_owner_file = [np.round(i) for i in list(pd_owner_tenant_raw['Current dwelling size'])]\n",
    "\n",
    "# assert area_tenant_file == area_owner_file #TODO for later 0 check which lines has error\n",
    "\n",
    "\n",
    "pd_owner_tenant_raw=pd_owner_tenant_raw.drop(columns=['Unnamed: 0', 'Step', 'Current dwelling id',\n",
    "                                                      'Current dwelling size','Postcode'])\n",
    "\n",
    "print('\\n\\nall columns=',list(pd_owner_tenant_raw.columns),len(list(pd_owner_tenant_raw.columns)))\n",
    "\n",
    "pd.DataFrame.to_csv(pd_owner_tenant_raw,'raw/1_households_building_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attached (owner-tenant) data to ---> input for building model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwelling_columns = list(pd_owner_tenant_raw.columns)[:21]\n",
    "pd_owner= pd_owner_tenant_raw[dwelling_columns]\n",
    "print(list(pd_owner.columns), len(list(pd_owner.columns)))\n",
    "pd.DataFrame.to_csv(pd_owner,'raw/1_dwelling_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attached (owner-tenant) data to ---> input for consumption model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tenant = pd_owner_tenant_raw.drop([ 'Year', 'Month','Dwelling room','Dwelling rent', 'building id', 'Settlment id', \n",
    "#                                       'Street address', 'city', 'post code', 'Building total apartment area', \n",
    "#                                       'Building no. of dwelling', 'Building height', 'Building Construction year', \n",
    "#                                       'Refurbishment year', 'Refurbishment type'],axis=1)\n",
    "# print(list(pd_tenant.columns),len(list(pd_tenant.columns)))\n",
    "# pd.DataFrame.to_csv(pd_tenant,'raw/1_households_data_noregion.csv',sep=',')\n",
    "\n",
    "# # Add the values in the 'char_region_xx' columns for consumption mdoel, based on postcodes in tenant model output\n",
    "# pd_tenant[['char_georegion_ge','char_georegion_mit','char_georegion_nw',\n",
    "#     'char_georegion_zh','char_georegion_ost','char_georegion_zen',\n",
    "#     'char_georegion_ti']] = pd.DataFrame([[0,0,0,0,0,0,0]], index=pd_tenant.index)\n",
    "\n",
    "# pd_tenant.loc[pd_tenant.canton=='Zurich', 'char_georegion_zh']=1\n",
    "# pd_tenant.loc[pd_tenant.canton=='Vaud', 'char_georegion_ge']=1\n",
    "\n",
    "# pd_tenant=pd_tenant.drop(['canton'],axis=1)\n",
    "\n",
    "\n",
    "# ## Prepare the file for input in consumption model, based on column names of tenant model output file\n",
    "# pd_consumption_raw_columns = pd.read_excel('model_tenant_ABM/Integration_ABMTenant_Consumptionmodel.xlsx')\n",
    "# pd_consumption_raw_columns_list = list(pd_consumption_raw_columns['variable_name_consumption_model'])\n",
    "\n",
    "# pd_tenant.columns = pd_consumption_raw_columns_list\n",
    "\n",
    "# print(list(pd_tenant.columns), len(list(pd_tenant.columns)))\n",
    "# pd.DataFrame.to_csv(pd_tenant,'raw/1_households_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tenant = pd.read_csv('model_tenant_ABM/strategy'+str(Strategy_no)+'_households_data.csv', sep=',')\n",
    "\n",
    "# Add the values in the 'char_region_xx' columns for consumption mdoel, based on postcodes in tenant model output\n",
    "pd_tenant[['char_georegion_ge','char_georegion_mit','char_georegion_nw',\n",
    "    'char_georegion_zh','char_georegion_ost','char_georegion_zen',\n",
    "    'char_georegion_ti']] = pd.DataFrame([[0,0,0,0,0,0,0]], index=pd_tenant.index)\n",
    "\n",
    "pd_tenant.loc[(pd_tenant.Postcode<9000) & (pd_tenant.Postcode>=8000) , 'char_georegion_zh']=1\n",
    "pd_tenant.loc[(pd_tenant.Postcode<2000) & (pd_tenant.Postcode>=1000), 'char_georegion_ge']=1\n",
    "\n",
    "pd_tenant=pd_tenant.drop(['Unnamed: 0', 'Year', 'Month', 'Postcode'],axis=1)\n",
    "print(list(pd_tenant.columns),len(list(pd_tenant.columns)))\n",
    "\n",
    "## Prepare the file for input in consumption model, based on column names of tenant model output file\n",
    "pd_consumption_raw_columns = pd.read_excel('model_tenant_ABM/Integration_ABMTenant_Consumptionmodel.xlsx')\n",
    "pd_consumption_raw_columns_list = list(pd_consumption_raw_columns['variable_name_consumption_model'])\n",
    "\n",
    "pd_tenant.columns = pd_consumption_raw_columns_list\n",
    "\n",
    "print(list(pd_tenant.columns), len(list(pd_tenant.columns)))\n",
    "pd.DataFrame.to_csv(pd_tenant,'raw/1_households_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attached (owner-tenant) data to ---> input for rebound model <a id='rebound-abm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the dwelling rent for income estimation\n",
    "pd_owner=pd.read_csv('raw/1_dwelling_data.csv',sep=',')[['Dwelling id','Dwelling rent']]\n",
    "pd_tenant_rebound=pd.merge(pd_tenant,pd_owner,left_on=['dwelling_id'],right_on=['Dwelling id'])\n",
    "\n",
    "# adapt the tenant database with the selected independent properties of the rebound regression model\n",
    "pd_rebound_column_name = list(pd.read_excel('model_rebound/integration_ABMTenant_Rebound.xlsx')['name_rebound'])\n",
    "pd_consum_column_name = list(pd.read_excel('model_rebound/integration_ABMTenant_Rebound.xlsx')['name_consumption']) \n",
    "\n",
    "# reindex the columns for input in the regression model\n",
    "pd_rebound = pd_tenant_rebound.T.reindex(pd_consum_column_name)\n",
    "\n",
    "pd_rebound = pd_rebound.T\n",
    "\n",
    "pd_rebound.columns = pd_rebound_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the columns further\n",
    "pd_rebound['disposable_income']=pd_rebound['disposable_income']*3 # assumption: rent is 1/3rd of the income\n",
    "pd.DataFrame.to_csv(pd_rebound,'raw/1_rebound_household_data.csv',sep=',',index=False)\n",
    "\n",
    "pd_rebound['households_with_a_woman_as_reference_person']=np.random.randint(0,2,pd_rebound.shape[0])\n",
    "\n",
    "sum1=pd_rebound['female_persons_aged_between_5_and_14_years']+pd_rebound[\n",
    "    'female_persons_aged_between_15_and_24_years']+pd_rebound[\n",
    "    'male_persons_aged_between_5_and_14_years']+pd_rebound[\n",
    "    'male_persons_aged_between_15_and_24_years']\n",
    "pd_rebound['number_of_students/trainees/apprentices_in_the_household']=np.random.randint(0,sum1+1,pd_rebound.shape[0])\n",
    "\n",
    "sum2=pd_rebound['female_persons_aged_between_25_and_34_years']+pd_rebound[\n",
    "    'female_persons_aged_between_35_and_44_years']+pd_rebound[\n",
    "    'female_persons_aged_between_45_and_54_years']+pd_rebound[\n",
    "    'female_persons_aged_between_55_and_64_years']+pd_rebound[\n",
    "    'male_persons_aged_between_25_and_34_years']+pd_rebound[\n",
    "    'male_persons_aged_between_35_and_44_years']+pd_rebound[\n",
    "    'male_persons_aged_between_45_and_54_years']+pd_rebound[\n",
    "    'male_persons_aged_between_55_and_64_years']\n",
    "pd_rebound['number_of_employed_persons_in_the_household']=np.random.randint(0,sum2+1,pd_rebound.shape[0])\n",
    "\n",
    "sum3 = pd_rebound['female_persons_aged_between_65_and_74_years']+pd_rebound[\n",
    "    'female_persons_older_than_75_years']+pd_rebound[\n",
    "    'male_persons_aged_between_65_and_74_years']+pd_rebound[\n",
    "    'male_persons_older_than_75_years']\n",
    "pd_rebound['number_of_employed_persons_in_the_household']=np.random.randint(0,sum3+1,pd_rebound.shape[0])\n",
    "\n",
    "pd_rebound['number_of_other_persons_in_the_household_(wrt_employment)']=0\n",
    "pd_rebound['number_of_self_employed_persons_in_the_household']=0\n",
    "pd_rebound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "## 1. Occupants' footprint <a id=\"consumption\"></a>\n",
    "\n",
    "<a href=\"#toc-main\">back</a>\n",
    "\n",
    "TOC:<a id=\"toc-consum\"></a>\n",
    "- <a href=\"#direct_cons\">Step 1.a. Direct Consumption-based footprint </a>\n",
    "- <a href=\"#rebounds\">Step 1.b. Rebounds of the consumption footrpint</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Direct Consumption-based footprint <a id=\"direct_cons\"></a>\n",
    "\n",
    "<a href=\"#toc-cons\">back</a>\n",
    "\n",
    "The following script assigns consumption-archetypes and associated life cycle greenhouse gas emissions that were found in the <a href=https://pubs.acs.org/doi/abs/10.1021/acs.est.8b01452>ES&T-Paper Froemelt et al. 2018</a> to the ABM-households. The assignment is conducted in the same manner as in the <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1111/jiec.12969\">JIE-Paper Froemelt et al. 2020</a> and thus based on the Random-Forest-Classifier that was trained for the respective paper.\n",
    "\n",
    "*Input*: the user needs to provide the data for the ABM-households in the same structure as demonstrated in test_data.xlsx\n",
    "\n",
    "*Run*: The Jupyter Notebook provides a step-by-step guidance to do the computations\n",
    "\n",
    "*Output*: Two EXCEL-files will be stored: 1. Probabilities for each household of behaving like a certain consumption-archetype; 2. LCA-results (IPCC 2013, 100a) aggregated at the main consumption areas for each household in kgCO$_{2}$-eq per year (NOTE: per household, not per capita)\n",
    "\n",
    "TOC <a id=\"toc\"></a>:\n",
    "- <a href=\"#ini\">Step 1a.0: Initialisation</a>\n",
    "- <a href=\"#prep\">Step 1a.1: Data Preparation</a>\n",
    "- <a href=\"#probs\">Step 1a.2: Estimate Probabilities for Consumption-Archetypes</a>\n",
    "- <a href=\"#lca\">Step 1a.3: Life Cycle Assessment of Consumption Behaviour</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.0: Initialisation <a id=\"ini\"></a>\n",
    "\n",
    "<a href=\"#toc\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data needed\n",
    "init_data_path = r\"model_consumption/Household-Model-Development/init_data\"\n",
    "# Path to output of ABM-model\n",
    "abm_input_path = r\"model_consumption/Household-Model-Development/abm_input\"\n",
    "# Separate path to classifier to save space on disk\n",
    "clf_path = r\"model_consumption\"\n",
    "# Path to results\n",
    "res_path = r\"model_consumption/Household-Model-Development/results\"\n",
    "\n",
    "# Loading classifier (trained and used for JIE-Paper Froemelt et al. 2020)\n",
    "with open(os.path.join(clf_path, \"calibrated_classifier_mob.pickle\"), 'rb') as f:\n",
    "    cccv = pickle.load(f)\n",
    "\n",
    "# Loading list of attributes (important for correct order of attributes)\n",
    "with open(os.path.join(init_data_path, 'listofattributes.pickle'), 'rb') as f:\n",
    "    listofattributes = pickle.load(f)\n",
    "    \n",
    "# Loading a translation dict to convert the random-forest-cluster-names to the names used in ES&T-Paper\n",
    "# Froemelt et al. 2018\n",
    "with open(os.path.join(init_data_path, 'archetransl.pickle'), 'rb') as f:\n",
    "    archetranslator = pickle.load(f)\n",
    "\n",
    "# Loading the LCA-results for greenhouse gas emissions (IPCC 2013, 100a) --> results are in kgCO2-eq/yr\n",
    "ghg_df = pd.read_pickle(os.path.join(init_data_path, 'archetypes_annual_ghg.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adapt the household consumption file slightly \n",
    "# nameofABMoutputfile_csv = pd.read_csv('raw/1_households_data.csv', sep=',')\n",
    "# nameofABMoutputfile_csv = nameofABMoutputfile_csv.iloc[:,5:37] # dropping first four columns which are not needed for the consumption model\n",
    "\n",
    "# nameofABMoutputfile_csv=nameofABMoutputfile_csv.drop_duplicates()\n",
    "\n",
    "# print(list(nameofABMoutputfile_csv.columns), len(list(nameofABMoutputfile_csv.columns)))\n",
    "# nameofABMoutputfile = nameofABMoutputfile_csv.to_excel('model_consumption/Household-Model-Development/abm_input/test_data.xlsx',\n",
    "#                                                             index = None, header=True) # ASSUMPTION: file is in xlsx-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(abm_input_path, \"test_data_\"+str(Strategy_no)+\".xlsx\")\n",
    "# fname = os.path.join(abm_input_path, \"new/test_data.xlsx\")\n",
    "agentHHs = pd.read_excel(fname)\n",
    "\n",
    "# Probably not necessary, but we are making sure that the attributes are in the correct order\n",
    "\n",
    "# agentHHs = agentHHs.T.reindex(listofattributes)\n",
    "# agentHHs = agentHHs.T\n",
    "# assert list(agentHHs.columns) == listofattributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.1: Data Preparation <a id=\"prep\"></a>\n",
    "\n",
    "<a href=\"#toc\">back</a>\n",
    "\n",
    "To impute the missing mobility data, two versions are implemented here. <a href=\"#mobv1\">Version 1</a>: set the mobility demand to the Swiss-wide median (=0.5); <a href=\"#mobv2\">Version 2</a>: Based on the given household characteristics, we estimate a mobility demand with microcensus data from 2015 (https://www.bfs.admin.ch/bfs/de/home/aktuell/neue-veroeffentlichungen.gnpdetail.2017-0076.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:blue\">USER INPUT NEEDED: CHOOSE <a href=\"#mobv1\">VERSION 1</a> OR <a href=\"#mobv2\">VERSION 2</a></p>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute mobility demand (Version 1, set to median) <a id=\"mobv1\"></a> and jump to <a href=\"#probs\">1a.2: Probabilities for Consumption-Archetypes</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentHHs['mobility'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impute mobility demand (Version 2, use microcensus 2015) <a id=\"mobv2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# daily distance in km from microcensus 2015 (motorisierter Individualverkehr):\n",
    "# Verkehrsverhalten der Bevölkerung, Kenngrössen 2015 - Schweiz\n",
    "mc_data = {\n",
    "    'gender': {\n",
    "        'm': 29.242695698,\n",
    "        'f': 19.595522015\n",
    "    },\n",
    "    'age': {\n",
    "        '0617': 13.252892803,\n",
    "        '1824': 24.792044371,\n",
    "        '2544': 31.295384917,\n",
    "        '4564': 28.671073552,\n",
    "        '6579': 16.968762215,\n",
    "        '8099': 6.5412771519\n",
    "        \n",
    "    },\n",
    "    'inc': {\n",
    "        '<4000': 13.196680471,\n",
    "        '40018000': 24.841538427,\n",
    "        '800112000': 32.139251131,\n",
    "        '>12000': 34.034484978\n",
    "    }\n",
    "}\n",
    "\n",
    "# Very probably, we will only have data on gender and age for the ABM-households --> income will not be considered\n",
    "# The following matchings are simplified assumptions to align the microcensus data with the expected data from the\n",
    "# ABM-model. If more detailed data is provided by the ABM-model the whole cell needs to be revised!\n",
    "matchABMMC = {\n",
    "    '0514': '0617',\n",
    "    '1524': '1824',\n",
    "    '2534': '2544',\n",
    "    '3544': '2544',\n",
    "    '4554': '4564',\n",
    "    '5564': '4564',\n",
    "    '6574': '6579',\n",
    "    '7599': '8099'\n",
    "}\n",
    "\n",
    "# Estimate daily mobility demand based on gender\n",
    "genderestimate = mc_data['gender']['f'] * \\\n",
    "agentHHs[[c for c in agentHHs.columns if 'fem' in c and not '0004' in c]].sum(axis=1) \\\n",
    "+ mc_data['gender']['m'] * agentHHs[[c for c in agentHHs.columns if 'male' in c and not '0004' in c]].sum(axis=1)\n",
    "\n",
    "# Estimate daily mobility demand based on age structure\n",
    "ageestimate = pd.Series(0, index=agentHHs.index)\n",
    "for ky in matchABMMC.keys():\n",
    "    ageestimate += (mc_data['age'][matchABMMC[ky]] * agentHHs[[c for c in agentHHs.columns if ky in c]].sum(axis=1))\n",
    "\n",
    "# Take the average of both estimates\n",
    "agentHHs['mobility'] = 0.5 * genderestimate + 0.5 * ageestimate\n",
    "\n",
    "# Convert from daily to yearly demand\n",
    "agentHHs['mobility'] *= 365\n",
    "\n",
    "# Load car demand of all Swiss households (mobility model --> see JIE-Paper Froemelt et al. 2020)\n",
    "hhcardemand = pd.read_pickle(os.path.join(init_data_path, 'allhhscardemand.pickle'))\n",
    "\n",
    "# Compute percentile score of agent-HHs' mobility demand\n",
    "for hhid in agentHHs.index:\n",
    "    agentHHs.loc[hhid, 'mobility'] = stats.percentileofscore(hhcardemand.values, agentHHs.loc[hhid, 'mobility']) / 100\n",
    "    \n",
    "del ageestimate, genderestimate, hhcardemand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.2: Probabilities for Consumption-Archetypes <a id=\"probs\"></a>\n",
    "\n",
    "<a href=\"#toc\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each ABM-household we compute the probability of being a certain consumption-archetype\n",
    "probs = cccv.predict_proba(agentHHs.values)\n",
    "probs_df = pd.DataFrame(data=probs, index=agentHHs.index, columns=[archetranslator[c] for c in cccv.classes_])\n",
    "\n",
    "# Visualise the probabilities\n",
    "sns.heatmap(probs_df, cmap='coolwarm', xticklabels=True, yticklabels=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Store the probabilities as excel-file\n",
    "probs_df.to_excel(os.path.join(res_path, 'res_archetypes_probas.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a.3: Life Cycle Assessment of Consumption <a id=\"lca\"></a>\n",
    "\n",
    "<a href=\"#toc\">back</a>\n",
    "\n",
    "Before a life cycle assessment of consumption behaviour can be performed, we have to choose a consumption-archetype for each ABM-household. There are two options for this: <a href=\"#lcav1\">Option 1</a> is a manual user choice; <a href=\"#lcav2\">Option 2</a> automatically chooses the most probable archetype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:blue\">USER INPUT NEEDED: CHOOSE <a href=\"#lcav1\">OPTION 1</a> OR <a href=\"#lcav2\">OPTION 2</a></p>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 1 (automatic selection of most probable archetype) <a id=\"lcav2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "archechoice = dict()\n",
    "maxprobas = probs_df.T.idxmax()\n",
    "for hhid in agentHHs.index:\n",
    "    archechoice[hhid] = maxprobas[hhid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2 (manual selection of archetypes) <a id=\"lcav1\"></a>\n",
    "\n",
    "<p style=\"color:blue\">USER INPUT NEEDED: ENTER THE ARCHETYPE-NAME (ACCORDING TO THE ES&T-PAPER FROEMELT ET AL. 2018) FOR EACH HOUSEHOLD</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archechoice = dict()\n",
    "for hhid in agentHHs.index:\n",
    "    archechoice[hhid] = input('HH-ID: {} --> Archetype: '.format(hhid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the final step, we assign the LCA-results to ABM-households and save them as an EXCEL-file\n",
    "\n",
    "**NOTE: The results are in kg CO$_{2}$-eq per year on a household level (not per capita!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the aggregated LCA-GHG-results to the ABM-households\n",
    "hh_lca_res = pd.DataFrame(np.nan, index=agentHHs.index, columns=[c for c in ghg_df.columns if not c.endswith('_cap')])\n",
    "for hhid in hh_lca_res.index:\n",
    "    archename = archechoice[hhid]\n",
    "    hh_lca_res.loc[hhid, hh_lca_res.columns] = ghg_df.loc[archename, hh_lca_res.columns]\n",
    "hh_lca_res.to_excel(os.path.join(res_path, 'res_hhlca.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attach the footprint back to tenants (1_household_data.csv)\n",
    "pd_result_consum_fp = pd.read_excel('model_consumption/Household-Model-Development/results/res_hhlca.xlsx',index_col=0)\n",
    "# pd_result_consum_fp = pd.concat([pd_tenant,pd_consum_fp],axis=1,sort=False)\n",
    "\n",
    "pd_result_consum_fp=pd_result_consum_fp.rename(columns={'total':'total_occupant_footprint'})\n",
    "\n",
    "pd_result_consum_fp['housing_all']=pd_result_consum_fp['housing']+pd_result_consum_fp['furnishings']\n",
    "pd_result_consum_fp['food_all']=pd_result_consum_fp['food']+pd_result_consum_fp['restaurantshotels']\n",
    "pd_result_consum_fp['transport_all']=pd_result_consum_fp['transport']+pd_result_consum_fp['recreation']\n",
    "\n",
    "\n",
    "pd.DataFrame.to_csv(pd_result_consum_fp,'postprocessing/1a_consumption/res_hhlca.csv')\n",
    "\n",
    "pd_result_consum_fp[['food_all','clothing','housing_all','transport_all','total_occupant_footprint']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "### 1b. Rebound consumption-based footprint <a id=\"rebounds\"></a>\n",
    "\n",
    "<a href=\"#toc-consum\">back</a>\n",
    "\n",
    "Aim: Quantify the environmental impact due to the savings due to consumption expenses\n",
    "\n",
    "_Input_: The household budet survey files to train the data \n",
    "\n",
    "_Model_: A random forest or Artificial neural network model \n",
    "<a href='https://ifu-esd-srv-4.ethz.ch/jupyterhub/user/shinder/notebooks/0_work/Models/1_consumption_movement/3_Rebound/5_final_model/rebound-model/rebound_model.ipynb'>Link to the full code</a>\n",
    "\n",
    "_Output_: The rebound expenses and environmental footprints of the households \n",
    "<p style='color:red'>[WIP] Detailed LCA of the consumption expenses as outputs</p>\n",
    "\n",
    "TOC<a id=\"toc-rebound\"></a>\n",
    "\n",
    "- <a href=\"#ini-rebound\"> Step 0: Initialisation</a>\n",
    "- <a href=\"#model-rebound\"> Step 1: Model </a>\n",
    "- <a href=\"#post-rebound\"> Step 2: Postprocessing </a>\n",
    "- <a href=\"#lca-rebound\"> Step 3: LCA </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b.0. Initialisation <a id = 'ini-rebound'></a>\n",
    "\n",
    "<a href=\"#toc-rebound\">back</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:blue'>USER INPUT NEEDED: based on the expected rebound analysis, change the following values</p>\n",
    "\n",
    "Data Parameters\n",
    "- (1) **habe_file_folder** -> For the year 2009-11, the main Household budget survey(habe/hbs) file is provided by <a href= https://pubs.acs.org/doi/full/10.1021/acs.est.8b01452>A.Froemelt</a>. It is modified based on original HBS(HABE) data that we <a href = https://www.bfs.admin.ch/bfs/en/home/statistics/economic-social-situation-population/surveys/hbs.html>obtain from Federal Statistical Office of Switzerland</a>. It is further modiefied in the <a href='https://ifu-esd-srv-4.ethz.ch/jupyterhub/user/shinder/notebooks/0_work/Models/1_consumption_movement/3_Rebound/5_final_model/rebound-model/rebound_model.ipynb'>original rebound code</a> in the preprocessing section\n",
    "- (2) **dependent_indices** -> based on the HBS column indices, this file lists the relevant consumption expense parameters which are predicted \n",
    "- (3) **independent_indices** -> the HBS column indices which define the household socio-economic properties\n",
    "- (4) **target_data** -> Selects the target dataset to predict the results. For this project on housing industry, it is the partner dataset 'ABZ', 'SCHL' or 'SM' (and here takes the input from the <a href='#rebound-abm'>ABMs output</a>)\n",
    "\n",
    "Model parameters\n",
    "- (1) **iter_n** -> no.of iterations of runs\n",
    "- (2) **model_name** -> Random Forest (RF) or ANN (Artificial Neural Network)\n",
    "- (3) **income_groups** -> for postprocessing, the number of income groups on which the result is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the preprocessed files (training data) in the original code (check link above to the code to generate them)\n",
    "habe_file_folder='model_rebound/preprocessing'\n",
    "\n",
    "# setting model parameters\n",
    "iter_n=2\n",
    "model_name='RF' # 'RF' or 'ANN'\n",
    "income_groups=5 \n",
    "\n",
    "scenarios = {'baseline_2011':500}\n",
    "target_data = 'ABZ_ABM' \n",
    "target_data_file= pd.read_csv('raw/1_rebound_household_data.csv',sep=',') \n",
    "pd.DataFrame.to_csv(target_data_file,'model_rebound/target_'+target_data+'.csv',sep=',',index=False)\n",
    "\n",
    "idx_column_savings_cons = 289 #289 = 'net_rent_and_mortgage_interest_of_principal_residence'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_indices= 'model_rebound/dependent_housing.csv'\n",
    "dependent_indices_pd = pd.read_csv(dependent_indices, delimiter=',', encoding='ISO-8859–1')\n",
    "dependent_indices_pd_name = pd.read_csv(dependent_indices,sep=',')[\"name\"]\n",
    "dependentsize=len(list(dependent_indices_pd_name))\n",
    "\n",
    "independent_indices='model_rebound/independent.csv' \n",
    "independent_indices_pd = pd.read_csv(independent_indices, delimiter=',', encoding='ISO-8859–1')\n",
    "list_independent_columns = pd.read_csv(independent_indices, delimiter=',', encoding='ISO-8859–1')['name'].to_list()\n",
    "list_dependent_columns = pd.read_csv(dependent_indices, delimiter=',', encoding='ISO-8859–1')['name'].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:blue'>USER INPUT NEEDED:Chose whether to normalise or not</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'no-normalise' #or 'normalise'\n",
    "\n",
    "if input =='normalise':\n",
    "    def normalise_partner(i,key):\n",
    "        pd_df_partner = pd.read_csv('model_rebound/target_'+target_data+'.csv',delimiter=',')\n",
    "        df_complete =  pd.read_csv('model_rebound/preprocessing/1_habe_rename_removeoutliers.csv',delimiter=',') \n",
    "        pd_df_partner['disposable_income'] = pd_df_partner['disposable_income'] + i\n",
    "\n",
    "        for colsss in list_independent_columns:\n",
    "            min_colsss = df_complete[[colsss]].quantile([0.01]).values[0]\n",
    "            max_colsss = df_complete[[colsss]].quantile([0.99]).values[0]\n",
    "            pd_df_partner[[colsss]] = (pd_df_partner[[colsss]] - min_colsss) / (max_colsss - min_colsss)\n",
    "\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,30]<=1]\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,32]<=1]\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,33]>=0] #todo remove rows with normalisation over the range\n",
    "\n",
    "        pd.DataFrame.to_csv(pd_df_partner,'model_rebound/preprocessing/5_final_'+ target_data + \n",
    "                            '_independent_final_'+str(i)+'.csv',sep=',',index=False)\n",
    "        return pd_df_partner\n",
    "\n",
    "if input =='no-normalise':\n",
    "    def normalise_partner(i,key):\n",
    "        pd_df_partner = pd.read_csv('model_rebound/target_'+target_data+'.csv',delimiter=',')\n",
    "        df_complete =  pd.read_csv('model_rebound/preprocessing/1_habe_rename_removeoutliers.csv',delimiter=',') \n",
    "        pd_df_partner['disposable_income'] = pd_df_partner['disposable_income'] + i\n",
    "\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,30]<=1]\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,32]<=1]\n",
    "        # pd_df_partner = pd_df_partner[pd_df_partner.iloc[:,33]>=0] #todo remove rows with normalisation over the range\n",
    "\n",
    "\n",
    "        pd.DataFrame.to_csv(pd_df_partner,'model_rebound/preprocessing/5_final_'+ target_data + '_independent_final_'+str(i)+'.csv',sep=',',index=False)\n",
    "        return pd_df_partner\n",
    "    \n",
    "for key in scenarios:\n",
    "    list_incomechange=[0,scenarios[key]]\n",
    "    for i in list_incomechange:\n",
    "        df_normalise_partner_file = normalise_partner(i,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b.1. Model <a id = 'model-rebound'></a>\n",
    "\n",
    "<a href=\"#toc-rebound\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_haushalts(values,id_ix=0):\n",
    "    haushalts = dict()\n",
    "    haushalt_ids = np.unique(values[:,id_ix])\n",
    "    for haushalt_id in haushalt_ids:\n",
    "        selection = values[:, id_ix] == haushalt_id\n",
    "        haushalts[haushalt_id] = values[selection]\n",
    "    return haushalts\n",
    "\n",
    "def split_train_test(haushalts,length_training,month_name,row_in_chunk):\n",
    "    train, test = list(), list()\n",
    "    cut_point = int(0.8*length_training)  # 0.9*9754 # declare cut_point as per the size of the imputed database #TODO check if this is too less\n",
    "    print('Month/cluster and cut_point',month_name, cut_point)\n",
    "    for k,rows in haushalts.items():\n",
    "        train_rows = rows[rows[:,row_in_chunk] < cut_point, :]\n",
    "        test_rows = rows[rows[:,row_in_chunk] > cut_point, :]\n",
    "        train.append(train_rows[:, :])\n",
    "        test.append(test_rows[:, :])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### NORMALISATION\n",
    "\n",
    "if input =='normalise':\n",
    "\n",
    "    def df_habe_train_test(df,month_name,length_training):\n",
    "        df=df.assign(id_split = list(range(df.shape[0])))\n",
    "        train, test = split_train_test(to_haushalts(df.values),length_training,month_name,row_in_chunk=df.shape[1]-1)\n",
    "\n",
    "        train_rows = np.array([row for rows in train for row in rows])\n",
    "        test_rows = np.array([row for rows in test for row in rows])\n",
    "\n",
    "        independent = list(range(0,independent_indices_pd.shape[0]))\n",
    "        dependent =  list(range(independent_indices_pd.shape[0]+1,\n",
    "                                independent_indices_pd.shape[0]+dependent_indices_pd.shape[0]+1))\n",
    "\n",
    "        trained_independent = train_rows[:, independent]\n",
    "        trained_dependent = train_rows[:, dependent]\n",
    "        test_independent = test_rows[:, independent]\n",
    "        test_dependent = test_rows[:, dependent]\n",
    "\n",
    "        ## OPTIONAL lines FOR CHECK - comment if not needed\n",
    "        np.savetxt('model_rebound/preprocessing/trained_dependent_nonexp.csv', trained_dependent, delimiter=',')    \n",
    "        np.savetxt('model_rebound/preprocessing/trained_dependent.csv', np.expm1(trained_dependent),delimiter=',')\n",
    "        np.savetxt('model_rebound/preprocessing/trained_independent.csv', trained_independent, delimiter=',')\n",
    "        np.savetxt('model_rebound/preprocessing/test_dependent.csv', np.expm1(test_dependent), delimiter=',')\n",
    "        np.savetxt('model_rebound/preprocessing/test_independent.csv', test_independent, delimiter=',')\n",
    "\n",
    "        return trained_independent,trained_dependent,test_independent,test_dependent\n",
    "\n",
    "    def df_partner_test(y):\n",
    "        df_partner = pd.read_csv('model_rebound/preprocessing/5_final_' + target_data + '_independent_final_' + str(y) + '.csv',\n",
    "                                 delimiter=',')\n",
    "        length_training = df_partner.shape[0]\n",
    "        train_partner, test_partner = split_train_test(to_haushalts(df_partner.values),length_training,month_name,1) \n",
    "        train_rows_partner = np.array([row for rows in train_partner for row in rows])\n",
    "        new_independent = list(range(0, 39)) # number of columns of the independent parameters\n",
    "        train_partner_independent = train_rows_partner[:, new_independent]\n",
    "\n",
    "        ### Optional lines for CHECK - comment if not needed\n",
    "        np.savetxt('model_rebound/preprocessing/train_partner_independent_' + model_name + '_' + str(y) + '.csv',\n",
    "                   train_partner_independent, delimiter=',')\n",
    "\n",
    "        return train_partner_independent\n",
    "    \n",
    "# NO-NORMALISATION\n",
    "if input =='no-normalise':\n",
    "    def df_habe_train_test(df,month_name,length_training):\n",
    "        df=df.assign(id_split = list(range(df.shape[0])))\n",
    "        train, test = split_train_test(to_haushalts(df.values),length_training,month_name,row_in_chunk=df.shape[1]-1)\n",
    "\n",
    "        train_rows = np.array([row for rows in train for row in rows])\n",
    "        test_rows = np.array([row for rows in test for row in rows])\n",
    "\n",
    "        independent = list(range(0,independent_indices_pd.shape[0]))\n",
    "        dependent =  list(range(independent_indices_pd.shape[0]+1,\n",
    "                                independent_indices_pd.shape[0]+dependent_indices_pd.shape[0]+1))\n",
    "\n",
    "        trained_independent = train_rows[:, independent]\n",
    "        trained_dependent = train_rows[:, dependent]\n",
    "        test_independent = test_rows[:, independent]\n",
    "        test_dependent = test_rows[:, dependent]\n",
    "\n",
    "        ## OPTIONAL lines FOR CHECK - comment if not needed\n",
    "        # np.savetxt('raw/checks/trained_dependent_nonexp_'+str(month_name)+'.csv', trained_dependent, delimiter=',')    \n",
    "        # np.savetxt('raw/checks/trained_independent_nonexp_'+str(month_name)+'.csv', trained_independent, delimiter=',')\n",
    "        np.savetxt('model_rebound/preprocessing/test_dependent_'+str(month_name)+'.csv', test_dependent,delimiter=',')    \n",
    "        np.savetxt('model_rebound/preprocessing/test_independent_'+str(month_name)+'.csv', test_independent, delimiter=',')\n",
    "\n",
    "        return trained_independent,trained_dependent,test_independent,test_dependent\n",
    "    \n",
    "    def df_partner_test(y):\n",
    "        df_partner = pd.read_csv('model_rebound/preprocessing/5_final_' + target_data + '_independent_final_' + str(y) + '.csv',\n",
    "                                 delimiter=',')\n",
    "        length_training = df_partner.shape[0]\n",
    "        train_partner, test_partner = split_train_test(to_haushalts(df_partner.values),\n",
    "                                                       length_training,cluster_number,1) \n",
    "        train_rows_partner = np.array([row for rows in train_partner for row in rows])\n",
    "        new_independent = list(range(0, 39))\n",
    "        train_partner_independent = train_rows_partner[:, new_independent]\n",
    "\n",
    "        ### Optional lines for CHECK - comment if not needed\n",
    "        np.savetxt('model_rebound/preprocessing/train_partner_independent_' + model_name + '_' + str(y) + '.csv',\n",
    "                   train_partner_independent, delimiter=',')\n",
    "\n",
    "        return train_partner_independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALISATION\n",
    "\n",
    "if input =='normalise':\n",
    "\n",
    "    def fit_predict_cluster(i,y,cluster_number,key):\n",
    "        df = pd.read_csv('model_rebound/preprocessing/4_habe_deseasonal_cluster_'+str(cluster_number)+'_normalised.csv',\n",
    "                         delimiter=',',error_bad_lines=False, encoding='ISO-8859–1')\n",
    "        length_training = df.shape[0]\n",
    "        trained_independent, trained_dependent, test_independent, test_dependent = df_habe_train_test(df,\n",
    "                                                                                                      str(cluster_number),\n",
    "                                                                                                      length_training)\n",
    "        train_partner_independent = df_partner_test(y)\n",
    "        \n",
    "        if model_name == 'ANN':\n",
    "            estimator = KerasRegressor(build_fn=ANN)\n",
    "            estimator.fit(trained_independent, trained_dependent, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "            ### PREDICTION FROM HERE\n",
    "            prediction_nn = estimator.predict(train_partner_independent)\n",
    "            prediction_nn_denormalised = np.expm1(prediction_nn)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) + '.csv', prediction_nn_denormalised, delimiter=',')\n",
    "\n",
    "            ### TEST PREDICTION\n",
    "            prediction_nn_test = estimator.predict(test_independent)\n",
    "            prediction_nn_test_denormalised = np.expm1(prediction_nn_test)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_test' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) + '.csv', prediction_nn_test_denormalised, delimiter=',')\n",
    "\n",
    "            ### CROSS VALIDATION FROM HERE\n",
    "            kfold = KFold(n_splits=10, random_state=12)\n",
    "            results1 = cross_val_score(estimator, test_independent, test_dependent, cv=kfold)\n",
    "            print(\"Results_test: %.2f (%.2f)\" % (results1.mean(), results1.std()))\n",
    "\n",
    "        if model_name == 'RF':\n",
    "            estimator = sko.MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_features=39, random_state=30))\n",
    "            estimator.fit(trained_independent, trained_dependent)\n",
    "\n",
    "            ### PREDICTION FROM HERE\n",
    "            prediction_nn = estimator.predict(train_partner_independent)\n",
    "            prediction_nn_denormalised = np.expm1(prediction_nn)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) + '.csv', prediction_nn_denormalised, delimiter=',')\n",
    "\n",
    "             ### TEST PREDICTION\n",
    "            prediction_nn_test = estimator.predict(test_independent)\n",
    "            prediction_nn_test_denormalised = np.expm1(prediction_nn_test)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_test' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) + '.csv', prediction_nn_test_denormalised, delimiter=',')        \n",
    "\n",
    "            #### CROSS VALIDATION FROM HERE\n",
    "            kfold = KFold(n_splits=10, random_state=12)\n",
    "            # results1 = cross_val_score(estimator, test_independent, test_dependent, cv=kfold)\n",
    "            results2 = r2_score(test_dependent,prediction_nn_test)\n",
    "            results3 = mean_squared_error(test_dependent,prediction_nn_test)\n",
    "            results4 = explained_variance_score(test_dependent,prediction_nn_test)\n",
    "            # print(\"cross_val_score: %.2f (%.2f)\" % (results1.mean(), results1.std()))\n",
    "            print(\"r2_score: %.2f \" % results2)\n",
    "            print(\"mean_squared_error: %.2f \" % results3)\n",
    "            print(\"explained_variance_score: %.2f \" % results4)\n",
    "\n",
    "### FOR NO NORMALISATION\n",
    "\n",
    "if input =='no-normalise':\n",
    "    def fit_predict_cluster(i,y,cluster_number,key):\n",
    "        df_non_normalised = pd.read_csv('model_rebound/preprocessing/4_habe_deseasonal_cluster_'+\n",
    "                                        str(cluster_number)+ '_short.csv', delimiter=',',\n",
    "                                        error_bad_lines=False, encoding='ISO-8859–1')\n",
    "        length_training = df_non_normalised.shape[0]\n",
    "        trained_independent, trained_dependent, test_independent, test_dependent = df_habe_train_test(df_non_normalised,\n",
    "                                                                                                      str(cluster_number),\n",
    "                                                                                                      length_training)\n",
    "        train_partner_independent = df_partner_test(y)\n",
    "        \n",
    "        ### Additional for the HBS test data subset\n",
    "        # test_new_independent = df_test(y,1) # chosing just one cluster here\n",
    "        # sratified_independent = df_stratified_test(y)\n",
    "    \n",
    "        if model_name == 'ANN':\n",
    "            estimator = KerasRegressor(build_fn=ANN)\n",
    "            estimator.fit(trained_independent, trained_dependent, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "            ### PREDICTION FROM HERE\n",
    "            prediction_nn = estimator.predict(train_partner_independent)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) +'.csv', prediction_nn, delimiter=',')\n",
    "\n",
    "            ### TEST PREDICTION\n",
    "            prediction_nn_test = estimator.predict(test_independent)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_test_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) +'.csv', prediction_nn_test, delimiter=',')\n",
    "\n",
    "            ### CROSS VALIDATION FROM HERE\n",
    "            kfold = KFold(n_splits=10, random_state=12)\n",
    "            results1 = cross_val_score(estimator, test_independent, test_dependent, cv=kfold)\n",
    "            print(\"Results_test: %.2f (%.2f)\" % (results1.mean(), results1.std()))\n",
    "\n",
    "        if model_name == 'RF':\n",
    "            estimator = sko.MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_features=39, random_state=30))\n",
    "            estimator.fit(trained_independent, trained_dependent)\n",
    "\n",
    "            ### PREDICTION FROM HERE\n",
    "            prediction_nn = estimator.predict(train_partner_independent)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) +'.csv', prediction_nn, delimiter=',')\n",
    "\n",
    "             ### TEST PREDICTION\n",
    "            prediction_nn_test = estimator.predict(test_independent)\n",
    "            np.savetxt('model_rebound/postprocessing/predicted_test_' + model_name + '_' + str(y) + '_' + str(i) \n",
    "                       + '_' + str(cluster_number) +'.csv', prediction_nn_test, delimiter=',')     \n",
    "\n",
    "            #### CROSS VALIDATION FROM HERE\n",
    "            kfold = KFold(n_splits=10, random_state=12)\n",
    "            # results1 = cross_val_score(estimator, test_independent, test_dependent, cv=kfold)\n",
    "            results2 = r2_score(test_dependent,prediction_nn_test)\n",
    "            results3 = mean_squared_error(test_dependent,prediction_nn_test)\n",
    "            results4 = explained_variance_score(test_dependent,prediction_nn_test)\n",
    "            # print(\"cross_val_score: %.2f (%.2f)\" % (results1.mean(), results1.std()))\n",
    "            # print(\"r2_score: %.2f \" % results2)\n",
    "            print(\"mean_squared_error: %.2f \" % results3)\n",
    "            print(\"explained_variance_score: %.2f \" % results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER of MONTHS - PREDICTIONS\n",
    "cluster_number_length = 7\n",
    "for cluster_number in list(range(1,cluster_number_length+1)):\n",
    "    print(cluster_number)\n",
    "    for j in range(0, iter_n):\n",
    "        for key in scenarios:\n",
    "            list_incomechange=[0,scenarios[key]]\n",
    "            for y in list_incomechange:\n",
    "                fit_predict_cluster(j,y,cluster_number,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b.2. Postprocessing <a id = 'post-rebound'></a>\n",
    "\n",
    "<a href=\"#toc-rebound\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_habe_outliers = pd.read_csv('model_rebound/preprocessing/1_habe_rename_removeoutliers.csv', delimiter =',')\n",
    "\n",
    "def average_pandas_cluster(y,cluster_number,key):\n",
    "    df_all = []\n",
    "    df_trained_partner = pd.read_csv('model_rebound/preprocessing/train_partner_independent_'+\n",
    "                                     model_name+'_'+str(y)+'.csv')\n",
    "    for i in range(0,iter_n):\n",
    "        df = pd.read_csv('model_rebound/postprocessing/predicted_' + model_name + '_' + \n",
    "                         str(y) + '_' + str(i) + '_' + \n",
    "                         str(cluster_number) + '.csv', delimiter = ',', header=None)\n",
    "        df_all.append(df)\n",
    "    glued = pd.concat(df_all, axis=1, keys=list(map(chr,range(97,97+iter_n))))\n",
    "    glued = glued.swaplevel(0, 1, axis=1)\n",
    "    glued = glued.groupby(level=0, axis=1).mean()\n",
    "    glued_new = glued.reindex(columns=df_all[0].columns)\n",
    "\n",
    "    max_income = df_habe_outliers[['disposable_income']].quantile([0.99]).values[0]\n",
    "    min_income = df_habe_outliers[['disposable_income']].quantile([0.01]).values[0]\n",
    "    glued_new['income'] = df_trained_partner[df_trained_partner.columns[-1]]\n",
    "    pd.DataFrame.to_csv(glued_new, 'model_rebound/postprocessing/predicted_' + model_name + '_' + str(y)\n",
    "                        + '_'+str(cluster_number)+'.csv', sep=',',header=None,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scenarios:\n",
    "    list_incomechange=[0,scenarios[key]]\n",
    "    for y in list_incomechange:\n",
    "        for cluster_number in list(range(1,cluster_number_length+1)):\n",
    "            average_pandas_cluster(y,cluster_number,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_categories_cluster(y,cluster_number):\n",
    "    df_income = pd.read_csv('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y)\n",
    "                            + '_'+str(cluster_number)+'.csv', \n",
    "                            sep=',',header=None)\n",
    "#     df_income['household_size'] = df_income.iloc[:, [17]]\n",
    "    df_income['income'] = df_income.iloc[:, [16]]\n",
    "    df_income['food'] = df_income.iloc[:,[0,1,2]].sum(axis=1)\n",
    "    df_income['misc'] = df_income.iloc[:,[3,4]].sum(axis=1)\n",
    "    df_income['housing'] = df_income.iloc[:, [5, 6]].sum(axis=1)\n",
    "    df_income['services'] = df_income.iloc[:, [7, 8, 9 ]].sum(axis=1)\n",
    "    df_income['travel'] = df_income.iloc[:, [10, 11, 12, 13, 14]].sum(axis=1)\n",
    "    df_income['savings'] = df_income.iloc[:, [15]]             \n",
    "    df_income = df_income[['income','food','misc','housing','services','travel','savings']]\n",
    "    pd.DataFrame.to_csv(df_income,\n",
    "                        'model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) \n",
    "                        + '_'+str(cluster_number)+'_aggregated.csv', sep=',',index=False)\n",
    "    return df_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scenarios:\n",
    "    list_incomechange=[0,scenarios[key]]\n",
    "    for y in list_incomechange: \n",
    "        for cluster_number in list(range(1,cluster_number_length+1)):\n",
    "            accumulate_categories_cluster(y,cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation of clusters\n",
    "\n",
    "list_dfs_month=[]\n",
    "for key in scenarios:\n",
    "    list_incomechange=[0,scenarios[key]]\n",
    "    for y in list_incomechange:    \n",
    "        for cluster_number in list(range(1,cluster_number_length+1)):\n",
    "            pd_predicted_month = pd.read_csv('model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) \n",
    "                                             + '_'+str(cluster_number)+'_aggregated.csv', delimiter = ',')\n",
    "            list_dfs_month.append(pd_predicted_month)\n",
    "\n",
    "        df_concat = pd.concat(list_dfs_month,sort=False)\n",
    "\n",
    "        by_row_index = df_concat.groupby(df_concat.index)\n",
    "        df_means = by_row_index.mean()\n",
    "        pd.DataFrame.to_csv(df_means,'model_rebound/postprocessing/predicted_' + model_name + '_' + str(y) + '_' + \n",
    "                            str(dependentsize) +'_aggregated.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rebounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dependent_columns = pd.read_csv(dependent_indices, delimiter=',', encoding='ISO-8859–1')['name'].to_list()\n",
    "\n",
    "def difference_new():\n",
    "    for cluster_number in list(range(1,cluster_number_length+1)):\n",
    "        for key in scenarios:\n",
    "            list_incomechange=[0,scenarios[key]]\n",
    "            for i in range(0,iter_n):\n",
    "                df_trained_partner = pd.read_csv('model_rebound/preprocessing/train_partner_independent_'+\n",
    "                                     model_name+'_'+str(y)+'.csv')\n",
    "                df_500 = pd.read_csv('model_rebound/postprocessing/predicted_' + model_name + '_'\n",
    "                                     +str(list_incomechange[1])+ '_'+str(i)\n",
    "                                     + '_'+str(cluster_number)+'.csv', delimiter=',',header=None)\n",
    "                df_0 = pd.read_csv('model_rebound/postprocessing/predicted_' + model_name + '_0_' \n",
    "                                    + str(i)  + '_'+str(cluster_number)+ '.csv', delimiter=',',header=None)\n",
    "                df_500.columns = list_dependent_columns\n",
    "                df_0.columns = df_500.columns\n",
    "                df_diff = df_500-df_0\n",
    "                df_diff['disposable_income']=df_trained_partner[df_trained_partner.columns[-1]]\n",
    "                pd.DataFrame.to_csv(df_diff,'model_rebound/postprocessing/predicted_' + model_name \n",
    "                                    + '_rebound_'+str(i)+ '_' + str(cluster_number) + '.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_clusters(key):\n",
    "    df_all = []\n",
    "    for i in range(0,iter_n):\n",
    "        df = pd.read_csv('model_rebound/postprocessing/predicted_'+ model_name + '_rebound_' + \n",
    "                         str(i)+ '_' + str(cluster_number)+'.csv',delimiter=',',index_col=None)\n",
    "        df_all.append(df)\n",
    "    \n",
    "    df_concat = pd.concat(df_all,sort=False)\n",
    "\n",
    "    by_row_index = df_concat.groupby(df_concat.index)\n",
    "    df_means = by_row_index.mean()\n",
    "    \n",
    "    pd.DataFrame.to_csv(df_means, 'model_rebound/postprocessing/predicted_'+model_name +'_rebound.csv',\n",
    "                        sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in scenarios:\n",
    "    average_clusters(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_categories(key):\n",
    "    df_income = pd.read_csv('model_rebound/postprocessing/predicted_'+model_name+ '_rebound.csv',delimiter=',')\n",
    "#     df_income['household_size'] = df_income.iloc[:, [17]]\n",
    "    df_income['income'] = df_income.iloc[:, [16]]\n",
    "    df_income['food'] = df_income.iloc[:,[0,1,2]].sum(axis=1)\n",
    "    df_income['misc'] = df_income.iloc[:,[3,4]].sum(axis=1)\n",
    "    df_income['housing'] = df_income.iloc[:, [5, 6]].sum(axis=1)\n",
    "    df_income['services'] = df_income.iloc[:, [7, 8, 9]].sum(axis=1)\n",
    "    df_income['travel'] = df_income.iloc[:, [10, 11, 12,13, 14]].sum(axis=1)\n",
    "    df_income['savings'] = df_income.iloc[:, [15]]    \n",
    "    df_income = df_income[['income','food','misc','housing','services','travel','savings']]#'transfers','total_sum'\n",
    "    data[key]=list(df_income.mean())\n",
    "    if list(scenarios.keys()).index(key) == len(scenarios)-1:\n",
    "        df = pd.DataFrame(data, columns = [key for key in scenarios],\n",
    "                  index=['income','food','misc','housing','services','travel','savings'])\n",
    "        print(df)\n",
    "        pd.DataFrame.to_csv(df, 'postprocessing/1b_rebound/rebound_results.csv', sep=',',index=True)\n",
    "    pd.DataFrame.to_csv(df_income,\n",
    "                        'postprocessing/1b_rebound/predicted_'+model_name+ '_rebound_aggregated.csv',\n",
    "                        sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}\n",
    "for key in scenarios:\n",
    "    accumulate_categories(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Average LCA impacts <a id = 'lca-rebound'></a>\n",
    "\n",
    "<a href=\"#toc-rebound\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------\n",
    "## 2. Material and renovation footprint of buildings<a id=\"toc-material-renovation\"></a>\n",
    "\n",
    "<a href=\"#toc-main\">back</a>\n",
    "\n",
    "\n",
    "TOC: \n",
    "- <a href = #material>2a. Material-based footprints</a>\n",
    "- <a href = #renovation>2b. Renovation-based footprints</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Material-based footprint <a id=\"material\"></a>\n",
    "\n",
    "<a href=\"#toc-material-renovation\">back</a>\n",
    "\n",
    "TOC:<a id=\"toc-material\"></a>\n",
    "\n",
    "- 2a.1. Building area and volume\n",
    "    - <a href = #building-data>(Approach1)</a> Taking the building area data directly from the partners\n",
    "    - <p style='color:red'><a href = #rene>(Approach2)</a> WIP: Mapping partners' to the building typology data (from <a href = 'https://www.sciencedirect.com/science/article/pii/S030626191731454X'>Rene Buffat research</a>, and from <a href='https://www.bfs.admin.ch/bfs/en/home/registers/federal-register-buildings-dwellings.html'>Federal register of buildings</a>)</p>\n",
    "- <a href = #material-impact>2a.2. Associating to the material intensity and impacts</a> (The material intensity used here is derived from the <a href='https://www.nature.com/articles/s41597-019-0021-x'>research by Niko Heeren & Tomer Fishman</a> )\n",
    "- <a href = #apartment>2a.3. Getting the results down to the apartment area</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style=\"color:blue\">USER INPUT NEEDED: CHOOSE <a href=\"#building-data\">OPTION 1</a> OR <a href=\"#rene\">OPTION 2</a></p>**\n",
    "\n",
    "### 2a.1. Building area and volume <a id=\"building-data\"></a>\n",
    "\n",
    "<a href=\"#toc-material\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Building total apartment area'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-959b049b32ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd_owner_building_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd_dwelling_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpd_owner_building_area\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd_owner_building_area\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Building total apartment area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m pd.DataFrame.to_csv(pd_owner_building_area,'postprocessing/2a_material/2_building_area.csv',\n\u001b[1;32m      8\u001b[0m                             sep=',', encoding='ISO-8859–1')\n",
      "\u001b[0;32m~/miniconda3/envs/integration-building-model/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/integration-building-model/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/integration-building-model/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Building total apartment area'] not in index\""
     ]
    }
   ],
   "source": [
    "pd_dwelling_data = pd.read_csv('raw/1_dwelling_data.csv',sep=',')\n",
    "pd_owner_building = pd_dwelling_data.drop_duplicates(subset=['building id'])\n",
    "pd.DataFrame.to_csv(pd_owner_building,'raw/2_building_owners_data.csv', sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "pd_owner_building_area = pd_dwelling_data.groupby(['building id'], as_index=False).sum()\n",
    "pd_owner_building_area=pd_owner_building_area[['building id','Building total apartment area']]\n",
    "pd.DataFrame.to_csv(pd_owner_building_area,'postprocessing/2a_material/2_building_area.csv',\n",
    "                            sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "\n",
    "#also rewrite the building area column of dwelling file \n",
    "pd_dwelling_data=pd.merge(pd_dwelling_data,pd_owner_building_area,on='building id')\n",
    "pd_dwelling_data=pd_dwelling_data.drop(['Building total apartment area_x'],axis=1)\n",
    "pd.DataFrame.to_csv(pd_dwelling_data,'raw/1_dwelling_data.csv',sep=',')\n",
    "\n",
    "pd_owner_building_area\n",
    "pd_dwelling_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<a href=\"#rene\">OPTION 2</a></p>** or jump to <a href=\"#material-impact\">2.2. material footprint</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a.1. Building area, height and volume (Buffat et al's model)<a id=\"rene\"></a>\n",
    "**<p style='color:red'> WIP </p>**\n",
    "\n",
    "<a href=\"#toc-material\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO - run the section below with GWS first and then this section with the Rene's model to merge the volume \n",
    "# (or make them work together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge apartments into buildings (drop the duplicate building id columns and drop the duplicate egids/coordinates)\n",
    "\n",
    "def partner_dropduplicate_egid(partners):\n",
    "    for partner in partners:\n",
    "        df_partner_raw_egid = pd.read_csv('raw/raw_partner_files/'+partner+'_EGIDEWID.csv', \n",
    "                                          delimiter=',', error_bad_lines=False, encoding='ISO-8859–1')\n",
    "        df_partner_raw_egid = df_partner_raw_egid.drop_duplicates(subset = ['EGID'])\n",
    "        pd.DataFrame.to_csv(df_partner_raw_egid,'postprocessing/2a_material/2a_'+partner+'_dropduplicate_egid.csv',\n",
    "                            sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "partner_dropduplicate_egid(['ABZ','SCHL'])\n",
    "\n",
    "def partner_dropduplicate_coordinates(partners):\n",
    "    for partner in partners:\n",
    "        df_partner_raw_coordinates = pd.read_csv('raw/raw_partner_files/'+partner+'_coordinates.csv', \n",
    "                                                 delimiter=',', error_bad_lines=False, encoding='ISO-8859–1')\n",
    "        df_partner_raw_coordinates = df_partner_raw_coordinates.drop_duplicates(subset = ['GKODES','GKODNS'])\n",
    "        pd.DataFrame.to_csv(df_partner_raw_coordinates,'postprocessing/2a_material/2a_'+partner+'_dropduplicate_coordinates.csv',\n",
    "                            sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "partner_dropduplicate_coordinates(['ABZ','SCHL','SM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optional to run - only run if the file is NOT present \n",
    "def truncate_buildinginfo():\n",
    "    df_buildinginfo_raw = pd.read_csv('raw/model_rene_buildinginfo/Buildinginfo.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    print(list(df_buildinginfo_raw.columns))\n",
    "    df_buildinginfo_raw = df_buildinginfo_raw[['btype','bid','bfsnr','x','y','elevation','area','volume',\n",
    "                                               'avg_height','perimeter']]\n",
    "    pd.DataFrame.to_csv(df_buildinginfo_raw, 'raw/model_rene_buildinginfo/Buildinginfo_truncated.csv')\n",
    "\n",
    "truncate_buildinginfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the owner ABM building-id files (based on the year and the partner, call the relevant 2c file to match)\n",
    "def matchbuildinginfo_coordinates(partner,year):\n",
    "    df_buildinginfo_raw = pd.read_csv('model_rene_buildinginfo/Buildinginfo_truncated.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    pd_partner = pd.read_csv('raw/2c_'+ partner + '_' + str(year) + '_coordinates.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    pd_material_partner = pd.merge(df_buildinginfo_raw,pd_partner,right_on=['GKODES','GKODNS'],left_on=['x','y'])\n",
    "    pd.DataFrame.to_csv(pd_material_partner,'raw/2d_'+ partner + '_' + str(year) + '_coordinates.csv')\n",
    "    \n",
    "def matchbuildinginfo_NN(partner,year):\n",
    "    df_buildinginfo_raw = pd.read_csv('model_rene_buildinginfo/Buildinginfo_truncated.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    pd_partner = pd.read_csv('raw/2c_'+ partner + '_' + str(year) + '_coordinates_NN.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    pd_material_partner = pd.merge(df_buildinginfo_raw,pd_partner,right_on=['gkodx_new','gkody_new'],left_on=['x','y'])\n",
    "    pd.DataFrame.to_csv(pd_material_partner,'raw/2d_'+ partner + '_' + str(year) + '_coordinates_NN.csv')\n",
    "\n",
    "# attach to the owner ABM building-id files (based on the year and the partner, call the relevant 2c file to match)\n",
    "def matchbuildinginfo_egid(partner,year):\n",
    "    df_buildinginfo_raw = pd.read_csv('model_rene_buildinginfo/Buildinginfo_truncated.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1') \n",
    "    #TODO add the merged version from coordinates\n",
    "    \n",
    "    pd_partner = pd.read_csv('raw/2c_'+ partner + '_' + str(year) + '_egid.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "    pd_material_partner = pd.merge(df_buildinginfo_raw,pd_partner,right_on=['egid'],left_on=['EGID_GWS'])\n",
    "    pd.DataFrame.to_csv(pd_material_partner,'raw/2d_'+ partner + '_' + str(year) + '_egid.csv')\n",
    "    \n",
    "for partner in ('ABZ', 'SCHL'):\n",
    "    for year in (2015, 2016, 2017):\n",
    "        matchbuildinginfo_coordinates(partner,year)\n",
    "        \n",
    "for partner in (['SM']):\n",
    "    for year in (2013,2014,2015,2016,2017):\n",
    "        matchbuildinginfo_NN(partner,year)\n",
    "        \n",
    "for partner in ('ABZ', 'SCHL'):\n",
    "    for year in (2013,2014):\n",
    "        matchbuildinginfo_egid(partner,year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GWS mapping to partner data (for other parameters like occupants, etc.)<a id=\"gws\"></a>\n",
    "\n",
    "<a href=\"#toc-material\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the EGID/coordinate data to the files from ABM owner part (with building ids)\n",
    "\n",
    "def partner_ownerABM_attach(partners,matchingstyle):\n",
    "    for partner in partners:\n",
    "        df_partner_raw_drop = pd.read_csv('postprocessing/2a_material/2a_'+partner+'_dropduplicate_'+matchingstyle+'.csv',\n",
    "                                      error_bad_lines=False, encoding='ISO-8859–1')\n",
    "\n",
    "        if partner == 'ABZ':\n",
    "            pd_owner_building_egid = pd.merge(pd_owner_building,df_partner_raw_drop, \n",
    "                                              left_on=['Settlment id', 'Street address'],\n",
    "                                              right_on=['Immobilien-Nr.', 'Hauseingang']) \n",
    "            \n",
    "            ## ********TODO - check with Margarita if these are the same settlement ids*************\n",
    "\n",
    "        if partner == 'SCHL':\n",
    "            pd_owner_building_egid = pd.merge(pd_owner_building,df_partner_raw_drop, \n",
    "                                              left_on=['Settlment id', 'Street address'],\n",
    "                                              right_on=['z', 'Adresse']) \n",
    "            \n",
    "            ## ********TODO - check with Margarita if these are the same settlement ids*************\n",
    "            \n",
    "        if partner == 'SM':\n",
    "            pd_owner_building_egid = pd.merge(pd_owner_building,df_partner_raw_drop, \n",
    "                                  left_on=['Settlment id', 'Street address'],\n",
    "                                  right_on=['ID', 'Corrected Address']) \n",
    "            \n",
    "        pd.DataFrame.to_csv(pd_owner_building_egid, 'postprocessing/2a_material/2b_'+partner+'_ownerABM_'+matchingstyle+'.csv',\n",
    "                            sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "partner_ownerABM_attach(['ABZ','SCHL','SM'],'coordinates')\n",
    "partner_ownerABM_attach(['ABZ','SCHL'],'egid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attach the building properties from GWS data\n",
    "\n",
    "## match with egid values\n",
    "\n",
    "def match_by_egid(partner,year):\n",
    "    df_GWS_GEB = pd.read_csv('raw/raw_GWS/GWS'+str(year)+'_GEB.txt', delimiter=';', \n",
    "                             error_bad_lines=False,encoding='ISO-8859–1')\n",
    "    \n",
    "    df_partner_raw = pd.read_csv('raw/2b_'+partner+'_ownerABM_egid.csv', delimiter=',', \n",
    "                                    error_bad_lines=False,encoding='ISO-8859–1')\n",
    "    \n",
    "    df_GWS_partner_egid = pd.merge(df_partner_raw, df_GWS_GEB, left_on=['EGID_GWS'], right_on=['egid'])\n",
    "    \n",
    "    pd.DataFrame.to_csv(df_GWS_partner_egid, 'raw/2c_' + partner + '_'+ str(year)+'_egid.csv', \n",
    "                        sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "\n",
    "    ## optional part - to increase the speed - and only check for specific cantons (NOTE: not applicable for SM)\n",
    "    if partner =='ABZ':\n",
    "        df_GWS_GEB=df_GWS_GEB[df_GWS_GEB['GDEKT'] == 'VD']\n",
    "        \n",
    "    if partner =='SCHL':\n",
    "        df_GWS_GEB = df_GWS_GEB[df_GWS_GEB['GDEKT'] == 'ZH']\n",
    "        \n",
    "        \n",
    "    df_GWS_partner_egid = pd.merge(df_partner_raw, df_GWS_GEB, left_on=['EGID_GWS'], right_on=['egid'])\n",
    "    \n",
    "    pd.DataFrame.to_csv(df_GWS_partner_egid,'raw/2c_'+partner+'_'+str(year)+'_egid_canton.csv',\n",
    "                        sep=',',encoding='ISO-8859–1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for year 2013,2014 and ABZ, SCHL - match the EGID values, for rest need to match by (nearest neighbor) geocoordinates\n",
    "for partner in ('ABZ', 'SCHL'):\n",
    "    for year in (2013,2014):\n",
    "        match_by_egid(partner,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## match with coordinate values\n",
    "\n",
    "def matchcoordinates(partner,year):\n",
    "    df_GWS_GEB = pd.read_csv('raw/raw_GWS/GWS'+str(year)+'_GEB.txt', delimiter=';', \n",
    "                             error_bad_lines=False,encoding='ISO-8859–1')\n",
    "        \n",
    "    df_partner_raw = pd.read_csv('raw/2b_'+partner+'_ownerABM_coordinates.csv', delimiter=',', \n",
    "                                    error_bad_lines=False,encoding='ISO-8859–1')\n",
    "    \n",
    "    df_partner_raw[\"GKODES\"] = df_partner_raw[\"GKODES\"].astype('int64')\n",
    "    df_partner_raw[\"GKODNS\"] = df_partner_raw[\"GKODNS\"].astype('int64')\n",
    "    \n",
    "    df_GWS_partner_coordinates = pd.merge(df_GWS_GEB, df_partner_raw, left_on=['GKODES', 'GKODNS'],\n",
    "                              right_on=['GKODES', 'GKODNS'])\n",
    "    \n",
    "    pd.DataFrame.to_csv(df_GWS_partner_coordinates, 'raw/2c_'+ partner + '_' + str(year) + '_coordinates.csv',\n",
    "                        sep=',', encoding='ISO-8859–1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year 2015,2016,2017 and for ABZ,SCHl - match by geocoordinates\n",
    "\n",
    "for partner in ('ABZ', 'SCHL'):\n",
    "    for year in (2015, 2016, 2017):\n",
    "        matchcoordinates(partner,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_node(node, nodes):\n",
    "    nodes = np.asarray(nodes)\n",
    "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "    return np.argmin(dist_2)\n",
    "\n",
    "def match_nn(partner,year):\n",
    "    df_GWS_GEB = pd.read_csv('raw/raw_GWS/GWS'+str(year)+'_GEB.txt', delimiter=';', \n",
    "                             error_bad_lines=False,encoding='ISO-8859–1')\n",
    "        \n",
    "    df_partner_GWS_raw = pd.read_csv('raw/2b_'+partner+'_ownerABM_coordinates.csv', delimiter=',',\n",
    "                                    error_bad_lines=False,encoding='ISO-8859–1')\n",
    "    nodes = []\n",
    "    for i in range(0, df_GWS_GEB.shape[0]):\n",
    "        node = np.array([df_GWS_GEB.iloc[i][\"GKODES\"], df_GWS_GEB.iloc[i][\"GKODNS\"]])\n",
    "        nodes.append(node)\n",
    "        \n",
    "    for i in range(df_partner_GWS_raw.shape[0]):\n",
    "        node = np.array([df_partner_GWS_raw.iloc[i][\"GKODES\"], \n",
    "                         df_partner_GWS_raw.iloc[i][\"GKODNS\"]])\n",
    "        x = closest_node(node, nodes)\n",
    "        df_partner_GWS_raw.at[i,\"min_distance_index\"] = closest_node(node, nodes)\n",
    "        df_partner_GWS_raw.at[i,\"gkodx_new\"] = df_GWS_GEB.iloc[x][\"GKODES\"]\n",
    "        df_partner_GWS_raw.at[i,\"gkody_new\"] = df_GWS_GEB.iloc[x][\"GKODNS\"]\n",
    "#         df_pd_partner_coordinates.at[i, \"GAPTO_\"+str(year)] = df_GWS_GEB.iloc[x][\"GAPTO\"] #to calculate occupants in that year\n",
    "#         df_pd_partner_coordinates[\"garea_new\"] = df_GWS_GEB.iloc[j][\"garea\"] #to calculate size of building in that year\n",
    "        \n",
    "    pd.DataFrame.to_csv(df_partner_GWS_raw,'raw/2c_'+partner+'_'+str(year)+'_coordinates_NN.csv', \n",
    "                        sep=',', encoding='ISO-8859–1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SM (all years) match by nearest neighbor geocoordinates\n",
    "for partner in (['SM']):\n",
    "    for year in (2013,2014,2015,2016,2017):\n",
    "        match_nn(partner,year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a.2. material footprint of buildings<a id=\"material-impact\"></a>\n",
    "\n",
    "<a href=\"#toc-material\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiply building volume with material intensity and get material weights\n",
    "pd_material_impact = pd.read_csv('model_material/intensity_material.csv',sep=',',index_col=0)\n",
    "pd_material_impact = pd_material_impact.T\n",
    "pd_material_impact_columns=list(pd_material_impact.columns)\n",
    "print(list(pd_material_impact.columns),'\\n',list(pd_material_impact.loc['kgco2-eq/ m2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the material weight per apartment based on apartment volume\n",
    "\n",
    "pd_material = pd.read_csv('postprocessing/2a_material/2_building_area.csv',sep=',')\n",
    "for i in pd_material_impact_columns:\n",
    "    pd_material[i]=pd_material['Building total apartment area']*pd_material_impact.loc['kgco2-eq/ m2'][i]\n",
    "pd_material['total_material_fp']=pd_material[pd_material_impact_columns].sum(axis=1)\n",
    "pd.DataFrame.to_csv(pd_material.drop('Unnamed: 0',axis=1),'postprocessing/2a_material/2_material_building_footprint.csv',sep=',')\n",
    "pd_material.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a.3. Material footprint of apartments<a id=\"apartment\"></a>\n",
    "\n",
    "<a href=\"#toc-material\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the material footprint (apartment) based on building vs apartment area\n",
    "pd_material_apart= pd.read_csv('raw/1_dwelling_data.csv', sep=',', encoding='ISO-8859–1')\n",
    "pd_owner_building_area= pd.read_csv('postprocessing/2a_material/2_building_area.csv',\n",
    "                            sep=',', encoding='ISO-8859–1')\n",
    "for i in pd_material_impact_columns:\n",
    "    pd_material_apart[i] =pd_material_apart['Dwelling area']*pd_material_impact.loc['kgco2-eq/ m2'][i]\n",
    "pd_material_apart['total_material_fp']=pd_material_apart[pd_material_impact_columns].sum(axis=1)\n",
    "pd.DataFrame.to_csv(pd_material_apart.drop('Unnamed: 0',axis=1),\n",
    "                    'postprocessing/2a_material/2_material_apartment_footprint.csv',sep=',')\n",
    "pd_material_apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get material footrpint per year \n",
    "pd_material_apart['total_material_fp_year'] = pd_material_apart['total_material_fp'] / (2020 - pd_material_apart['Building Construction year'])\n",
    "pd.DataFrame.to_csv(pd_material_apart.drop('Unnamed: 0',axis=1),\n",
    "                    'postprocessing/2a_material/2_material_apartment_footprint.csv',sep=',')\n",
    "pd_material_apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_material_apart[['total_material_fp_year']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_material_apart=pd_material_apart[(pd_material_apart[['total_material_fp_year']] > -300).all(1)]\n",
    "pd_material_apart[['total_material_fp_year']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------\n",
    "## 2b. Renovation footprints  <a id=\"renovation\"></a>\n",
    "\n",
    "<a href=\"#toc-material-renovation\">back</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Energy demand and footprint <a id=\"energy\"></a>\n",
    "\n",
    "<a href=\"#toc-main\">back</a>\n",
    "\n",
    "TOC:<a id=\"#toc-energy\"></a>\n",
    "- <a href=\"heat\">Step 3.a. Heat energy based footrpint of apartment</a>\n",
    "- <a href=\"ww\">Step 3.b. Warm water based footrpint of apartment</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a. Heat energy based footrpint <a id=\"heat\"></a>\n",
    "\n",
    "The model, called as <a href=\"https://www.scopus.com/record/display.uri?eid=2-s2.0-85076259074&origin=inward&txGid=67727348b41d9ae4dc4b55e19b8b2646\">BEEF</a> (building energy environmental footprint) is developed by Rene Buffat and Andreas Froemelt.\n",
    "\n",
    "<a href=\"#toc-energy\">back</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:red'>WIP: RUnning the beef model directly based on the inputs</p>\n",
    "\n",
    "- run the beef model by going to the right environment (beef_model/bin/activate) -> activate it. \n",
    "- for a quick fix to run the model, the existing run results and outputs are directly passed here and the subset of results are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pass the building ids and the building details to BEEF model (get heating demand)\n",
    "df_beef = pd.read_csv('model_beef/x-model_beef_energy/Beef_heatingdemand.csv', delimiter=',', \n",
    "                          error_bad_lines=False, encoding='ISO-8859–1')\n",
    "\n",
    "df_beef = df_beef[['btype', 'bid', 'bfsnr', 'ebf', 'egid', 'x', 'y', 'wall_method','heatdemand_y_median']]\n",
    "df_beef['total_heatdemand_median'] = df_beef['ebf']*df_beef['heatdemand_y_median']\n",
    "pd.DataFrame.to_csv(df_beef, 'model_beef/x-model_beef_energy/Buildinginfo_truncated.csv')\n",
    "print(df_beef.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## match the partner egids and geocoordinates with the beef model results\n",
    "\n",
    "pd_partners_EGID_coordinates = pd.read_csv('raw/raw_partner_files/Partner_EGID_coordinates_'+str(Strategy_no)+'.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "\n",
    "#write file by matching egids for buildings\n",
    "pd_energy_partner = pd.merge(df_beef,pd_partners_EGID_coordinates,left_on=['egid'],right_on=['EGID'])\n",
    "pd_energy_partner=pd_energy_partner.rename(columns={'total_heatdemand_median':'heatdemand_median_egid'})\n",
    "\n",
    "print('egid_matching',pd_energy_partner.shape)\n",
    "\n",
    "pd.DataFrame.to_csv(pd_energy_partner,'postprocessing/2b_energy/2b_energy_demand_egid.csv',sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "\n",
    "#write file by matching coordinates fro buildings\n",
    "pd_energy_partner_coordinates= pd.merge(df_beef,pd_partners_EGID_coordinates,left_on=['x','y'],right_on=['GKODES','GKODNS'])\n",
    "pd_energy_partner_coordinates= pd_energy_partner_coordinates.rename(columns={'total_heatdemand_median':'heatdemand_median_coordinates'})\n",
    "print('coordinate_matching',pd_energy_partner_coordinates.shape)\n",
    "\n",
    "pd.DataFrame.to_csv(pd_energy_partner_coordinates,'postprocessing/2b_energy/2b_energy_demand_coordinates.csv',\n",
    "                    sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "\n",
    "#write final file with all energy heating demands for buildings\n",
    "pd_energy = pd.concat([pd_energy_partner,pd_energy_partner_coordinates])\n",
    "pd_energy['heatdemand']=pd_energy[['heatdemand_median_egid','heatdemand_median_coordinates']].max(axis=1)\n",
    "pd_energy=pd_energy.drop_duplicates(subset=['Partner', 'Immobilien-Nr.', 'EGID','bid','bfsnr','wall_method'])\n",
    "print('all_matching',pd_energy.shape)\n",
    "\n",
    "pd.DataFrame.to_csv(pd_energy,'postprocessing/2b_energy/2b_energy_demand.csv',sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "# add heat demand per settlement \n",
    "pd_energy_settlement = pd_energy.groupby(['Settlement ID'],as_index=False)['heatdemand'].sum()\n",
    "print('all_matching_settlements',pd_energy_settlement.shape)\n",
    "pd.DataFrame.to_csv(pd_energy_settlement,'postprocessing/2b_energy/2b_energy_demand_settlement.csv',\n",
    "                    sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "pd_energy_settlement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the total area of settlementand allocate it to the dwellings\n",
    "pd_energy_apart= pd.read_csv('raw/1_dwelling_data.csv', sep=',', encoding='ISO-8859–1')\n",
    "\n",
    "#merge the dwelling data with the heat demand per settlement\n",
    "pd_energy_apart=pd.merge(pd_energy_apart,pd_energy_settlement,left_on=['Settlment id'],right_on=['Settlement ID'])\n",
    "\n",
    "pd_energy_apart['heatdemand_building']=pd_energy_apart.groupby(['building id'],as_index=False)['heatdemand'].transform('mean')\n",
    "pd_energy_apart['Building total apartment area']=pd_energy_apart.groupby([\n",
    "    'building id'],as_index=False)['Dwelling area'].transform('sum')\n",
    "pd_energy_apart['heatdemand_m2']=pd_energy_apart['heatdemand_building']/pd_energy_apart['Building total apartment area']*5\n",
    "pd_energy_apart=pd_energy_apart.drop(['Unnamed: 0','Unnamed: 0.1','Building total apartment area_y'],axis=1)\n",
    "\n",
    "# get the heatdemand per apartment\n",
    "\n",
    "pd_energy_apart['heatdemand_final_kWh']=0.28*pd_energy_apart['heatdemand_m2']*pd_energy_apart['Dwelling area']\n",
    "pd.DataFrame.to_csv(pd_energy_apart,'postprocessing/2b_energy/2_energy_demand_final.csv',sep=',', encoding='ISO-8859–1')\n",
    "pd_energy_apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attach the energy source <a id='source'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color:blue'> USER INPUT NEEDED: <a href=\"https://docs.google.com/spreadsheets/d/1viAxbRDI8qwE4RVF9LEO8MrN89zV4Y7WYTqQZ0eatTE/edit#gid=1766015530\">Change the strategy no. based on Forum Thun Srategies</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## attach the heating source and multiply the demand with relevant energy source footprint\n",
    "pd_partners_EGID_energy = pd.read_csv('raw/raw_partner_files/Partner_EGID_coordinates_'+str(Strategy_no)+'.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')[['Settlement ID','heat_source','impact_kwh']]\n",
    "pd_energy_apart= pd.read_csv('postprocessing/2b_energy/2_energy_demand_final.csv', delimiter=',', \n",
    "                              error_bad_lines=False, encoding='ISO-8859–1')\n",
    "\n",
    "pd_energy_apart_fp=pd.merge(pd_energy_apart,pd_partners_EGID_energy,on=['Settlement ID'])\n",
    "\n",
    "pd_energy_apart_fp['total_energy_fp']=pd_energy_apart_fp['heatdemand_final_kWh']*pd_energy_apart_fp['impact_kwh']\n",
    "\n",
    "pd.DataFrame.to_csv(pd_energy_apart_fp,'postprocessing/2b_energy/2_energy_apartment_footprint.csv')\n",
    "pd_energy_apart_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_energy_apart_fp.groupby(['heat_source'], as_index=False)['total_energy_fp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_energy_apart_fp[['total_energy_fp']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b. Warm water based footprint<a id=\"ww\"></a>\n",
    "\n",
    "<a href=\"#toc-energy\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attach he warm water requirements from the partner data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimate the warm water requirement based on the occupants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## covert to the apartment data based on the occupants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the energy footprint (apartment) - - multiply based on warmwater source \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integrate all the three footprints<a id=\"total_impacts\"></a>\n",
    "\n",
    "<a href=\"#toc-main\">back</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_occupant_footprint = pd.read_csv('postprocessing/1a_consumption/res_hhlca.csv',sep=',')\n",
    "pd_material_footprint = pd.read_csv('postprocessing/2a_material/2_material_apartment_footprint.csv',sep=',')\n",
    "pd_energy_footprint = pd.read_csv('postprocessing/2b_energy/2_energy_apartment_footprint.csv',sep=',')\n",
    "\n",
    "\n",
    "pd_final = pd.merge(pd_occupant_footprint[['timestep', 'dwelling_id', 'dwelling_size', 'hhid', \n",
    "                                          'char_nopers','food_all','housing_all','transport_all','total_occupant_footprint']],\n",
    "                    pd_material_footprint[['Time step', 'Dwelling id', 'Dwelling room', 'Dwelling area', 'Dwelling rent', \n",
    "                                           'building id', 'Settlment id', 'Street address', 'post code', \n",
    "                                           'city', 'canton', 'Building Construction year','total_material_fp_year']],\n",
    "                    left_on=['timestep','dwelling_id'],\n",
    "                    right_on=['Time step','Dwelling id'])\n",
    "\n",
    "pd_final=pd.merge(pd_final,pd_energy_footprint[['Time step','Dwelling id','heat_source','Building total apartment area','total_energy_fp']],\n",
    "                  on=['Time step','Dwelling id'])\n",
    "\n",
    "pd_final = pd_final.drop(['Time step','Dwelling id','Dwelling area'],axis=1)\n",
    "\n",
    "pd_final = pd_final[['timestep', 'dwelling_id',  'hhid', 'char_nopers',  \n",
    "            'dwelling_size','Dwelling room', 'Dwelling rent', \n",
    "            'building id', 'Settlment id', 'Street address', 'post code', 'city', 'canton', \n",
    "            'heat_source', 'Building Construction year','Building total apartment area', \n",
    "                     'food_all','housing_all','transport_all',\n",
    "            'total_occupant_footprint','total_material_fp_year', 'total_energy_fp']]\n",
    "\n",
    "\n",
    "pd.DataFrame.to_csv(pd_final,'postprocessing/4_all_footprints_'+str(Strategy_no)+'.csv',sep=',')\n",
    "pd_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final[['total_occupant_footprint','total_material_fp_year', 'total_energy_fp']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all strategies\n",
    "# for i in [0,1,2,3,4]:\n",
    "#     pd_final=pd.read_csv('postprocessing/4_all_footprints_'+str(i)+'.csv')\n",
    "pd_final.groupby(['dwelling_id'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_final.groupby(['heat_source'], as_index=False)['total_energy_fp'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all strategies\n",
    "# for i in [0,1,2,3,4]:\n",
    "#     pd_final=pd.read_csv('postprocessing/4_all_footprints_'+str(i)+'.csv')      \n",
    "pd_final.groupby(['char_nopers'], as_index=False)['total_occupant_footprint'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_occupant_energy_out = pd_final.groupby(['char_nopers'], as_index=False)['total_energy_fp'].mean()\n",
    "pd_occupant_energy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(pd_occupant_energy_out['char_nopers']),list(pd_occupant_energy_out['total_energy_fp']), 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_construction = pd_final.groupby(['Building Construction year'], as_index=False)['total_material_fp_year'].mean()\n",
    "pd_construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(pd_construction['Building Construction year'])[:-2],list(pd_construction['total_material_fp_year'])[:-2], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:integration-building-model]",
   "language": "python",
   "name": "conda-env-integration-building-model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
